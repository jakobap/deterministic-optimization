{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deterministic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "__Concavity of the function:__\n",
    "\n",
    "The objective function $l(K|S)=\\log(det(K))-tr(SK)$ is concave since $tr(SK)$ is linear in $K$, whilst $\\log(det(K))$ is concave over any line $(1-t)K+tB$ given that $K$ and $B$ are PD matrices. \n",
    "\n",
    "This is easily proven considering that \n",
    "\n",
    " $$log(det((1-t)K + tB) =log(det(K^{\\frac{1}{2}}((1-t)I+tK^{-\\frac{1}{2}}BK^{-\\frac{1}{2}})K^{\\frac{1}{2}})=log(det((1-t)K))+\\sum{log((1-t)+t\\lambda_i})$$\n",
    "\n",
    "Since the logarithm of the determinant is a constant, and $\\log(1+t\\lambda_i)$ is concave in t, the whole function is concave.\n",
    "\n",
    "The set M is convex since, for $K \\in M$, any matrix of the type $(1-t)B+tK, t \\in [0,1]$ will also be in M, since both t and 1-t are obviously positive so no element change sign.\n",
    "\n",
    "\n",
    "\n",
    "__Problem formalation:__\n",
    "\n",
    "\n",
    "\n",
    "- __Lagrangian__:\n",
    "\n",
    "\\begin{align}\n",
    "  l^* & = -l(K|S) + \\lambda^Tg(K) \\\\\n",
    "  \\\\\n",
    "  g_{ij}(x)  & : x_{ij} \\leq 0 \\text{ for $i\\neq j$} \\\\\n",
    "  h_{jj}(x)  & : x_{ij} - x_{ji} = 0 \\leq 0\n",
    "\\end{align}\n",
    "  \n",
    "\n",
    "- __Duality problem:__ One approach to the problem can be to take the supermum for all non negative lambdas of the infimum for all K's of the Lagrangian which is now  a function of lambda.\n",
    "\n",
    "$$ \\inf_{\\lambda^*\\geq0}\\sup_{K\\in R^{d \\times d}} (l^*(K|S) - \\lambda^T * g(K))$$\n",
    "\n",
    "For any $\\lambda \\geq 0$, we know that the dual function sets a lower bound on the optimal value of $l$ and thus (a fortiori) on the maximum of the objective function\n",
    "\n",
    "- __KKT conditions:__\n",
    "Let $\\lambda^* \\in R^m$ be the optimal dual vector and $K^* \\in R^{d \\times d}$ the optimal primal vector. The following conditions are necessary and sufficient for $K^*$ to be the global optimum.\n",
    "\n",
    "- __Primal Feasibility:__  $g(K^*) \\leq 0$.\n",
    "\n",
    "- __Dual Feasibility:__ $\\lambda^* \\geq 0$.\n",
    "\n",
    "- __Complementary Slackness:__ $\\lambda^*_i g_i=0 \\text{ for i=1, ..., m}$.\n",
    "\n",
    "- __Lagrangian Condition:__ The pair $(K^*, \\lambda^*)$ satisfies\n",
    "\n",
    "$$\\nabla_K L(K^* , \\lambda^*) =\\nabla f(K^*)+\\sum_{i=1}^{m} \\lambda^*_i \\nabla g_i (K^*)  = 0 $$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__Observation 1:__ This is a the formal problem setup. Computationally, taking advantage of the simetry of the proble,  we reduce the search spaces from to  $R^{d \\times d}$  $R^{\\frac{(d-1)d}{2}}$.\n",
    "\n",
    "__Observation 2:__ It is not necessary to control for $K$ been $PSD$ explicitely as a set of conditions.\n",
    "\n",
    "__Proof:__\n",
    "First we will proof that $A = \\{K \\in PSD\\}$ is an open set and $\\partial A$ is equal to the $\\{K s.t. \\det(K)=0\\}$\n",
    "\n",
    "For each diagonal matrix $D$ s.t. all the eigen-values are positive we can think of the $O^t \\times D \\times O$. \n",
    "Where $O = \\{M \\in R^{d \\times d} s.t. M^t M = I\\}$.\n",
    "Now when we consider this  product for all diagonal matrices, this is an open set. It's boundary are elements whose eigen-values contain zeros or infinete.\n",
    "\n",
    "The value of our function in the boundary is $-\\infty$ therefore, since the optimizer would never follow a descending path, if we star inside A we continue on A.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "also installing the dependencies ‘desc’, ‘pkgbuild’, ‘rprojroot’, ‘pkgload’, ‘praise’, ‘rlang’, ‘rex’, ‘Rmpfr’, ‘testthat’, ‘nnls’, ‘slam’, ‘covr’\n",
      "\n",
      "Updating HTML index of packages in '.Library'\n",
      "Making 'packages.html' ... done\n"
     ]
    }
   ],
   "source": [
    "# install.packages(\"psych\")\n",
    "# install.packages('CVXR')\n",
    "# install.packages(\"MASS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(psych)\n",
    "library(MASS)\n",
    "library(ggplot2)\n",
    "# library(CVXR)\n",
    "options(warn=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "To have a benchmark for the optimization, we used the standard R library for convex optimization, CVXR: https://cvxr.rbind.io/\n",
    "\n",
    "The optimization was subject to two constraints. Firstly, the PSD constraint, which we defined in the Variable. Secondly negative values off the diaginal of K, which we defined on an object basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "exercise_2 <- function(S, pre = 1e-1, max_iter = 100){\n",
    "  n <- dim(S)[1]\n",
    "  \n",
    "  K  <- Variable(n, n, PSD = TRUE)     ## Variable constrained to positive semidefinite cone\n",
    "  \n",
    "  obj <- Maximize(log_det(K) - matrix_trace(S %*% K))\n",
    "\n",
    "  ix <- 1\n",
    "  constr <- list()\n",
    "  \n",
    "  for (i in 1:n){\n",
    "    for (j in 1:n){\n",
    "      if (i == j){\n",
    "        constr[ix] <- K[i, j] >= 0\n",
    "      }else{\n",
    "        constr[ix] <- K[i, j] <= 0\n",
    "      }\n",
    "      ix <- ix + 1\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  prob <- Problem(obj,constr)\n",
    "  result <- solve(prob)\n",
    "\n",
    "  return(list(result$solve_time, result$num_iters, round(result$getValue(K),2)))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "To develop an algorithm capable of beating general-purpose frameworks in this concrete problem, we have leverage on the following ideas:\n",
    "\n",
    "\n",
    "- __Coordinate-wise vs Gradient Optimization:__ Gradient is faster if it's not taken into account the time to calculate the gradient. In this type of problem, the cost of this step grows quadratically with the size of the matrix $(n)$.\n",
    "\n",
    "\n",
    "- __Speeding up the calculation of the function:__ The function to maximize $ f(x) = \\log(\\det(K)) - tr(SK) $ is also computationally  expensive. The determinant of a matrix grows as $n!$. Taking advantage of the former decision  (coordenate-wise optimization), condition  on $x_{ii}, \\det(K)$ it's a linear function and condition on $x_{ij}, \\det(K)$ is a quadratic function. Thus once we've chosen the coordinate we will optimize on, we precalculate the function $\\det(K)$ as a function of $x_{ij}$ or $x_{ii}$.\n",
    "\n",
    "\n",
    "- __Turning the problem into an unconstrained problem__: The original optimization problem is constrained to $x_{ij} \\leq 0$ and $ x_{ij} \\geq 0$ insted of optimizing  $f(x_{ij}$ we will optimize $f(-x_{ij}^2$ and instead of optimizing $f(x_{ii})$ we will optimize $f(x_{ii}^2)$\n",
    "\n",
    "\n",
    "- __Choosing the initial point:__ The original problem is concave. The unconstrained version $f(-x_{ij}^2), f(x_{ii}^2)$ has $\\frac{(n-1)n}{2}$ minimums. In particular diagonal matrices $D$ lay in the boundary of two convergence regions. Thus these are the type of point not to start with. We have chosen $Id - \\epsilon $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So let's get started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poli_det\n",
    "\n",
    "This function generates the polynomial expression of $\\det(K)$ condition to $x_{ij}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "poli_det <- function(K, i, j){\n",
    "  if (i==j){\n",
    "    # Calculate\n",
    "    K[i, j] <- 0\n",
    "    V0 <- det(K)\n",
    "    K[i, j] <- 1\n",
    "    V1 <- det(K)\n",
    "    \n",
    "    # Solve\n",
    "    c <- V0\n",
    "    a <- V1 - c\n",
    "    \n",
    "    f <- function(x){\n",
    "      a*x + c\n",
    "    }\n",
    "  }else{\n",
    "    # Calculate\n",
    "    K[i, j] <- 0\n",
    "    K[j, i] <- 0\n",
    "    V0 <- det(K)\n",
    "    K[i, j] <- 1\n",
    "    K[j, i] <- 1\n",
    "    V1 <- det(K)\n",
    "    K[i, j] <- -1\n",
    "    K[j, i] <- -1\n",
    "    V_1 <- det(K)\n",
    "    \n",
    "    # Solve\n",
    "    c <- V0\n",
    "    a <- (V1 + V_1 - 2*c)/2\n",
    "    b <- V1 - c - a\n",
    "    \n",
    "    f <- function(x){\n",
    "      a*x^2+b*x++c\n",
    "    }\n",
    "  }\n",
    "  f\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poli_trace\n",
    "Calculates the polinomyal expression of $tr(SK)$ condition on $x{ij}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "poli_trace <- function(S, K, i, j){\n",
    "  if(i==j){\n",
    "    # Calculate\n",
    "    K[i, j]<- 0\n",
    "    V0 <- tr(S%*%K)\n",
    "    K[i, j]<- 1\n",
    "    V1 <- tr(S%*%K)\n",
    "    \n",
    "    # Solve\n",
    "    b <- V0\n",
    "    a <- V1 - b\n",
    "    \n",
    "    f <- function(x){\n",
    "      a*x+b\n",
    "    }\n",
    "  }else{\n",
    "    # Calculate\n",
    "    K[i, j] <- 0\n",
    "    K[j, i] <- 0\n",
    "    V0 <- tr(S%*%K)\n",
    "    K[i, j] <- 1\n",
    "    K[j, i] <- 1\n",
    "    V1 <- tr(S%*%K)\n",
    "\n",
    "    # Solve\n",
    "    b <- V0\n",
    "    a <- V1 - b\n",
    "    \n",
    "    f <- function(x){\n",
    "      a*x+b\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poli_fun\n",
    "\n",
    "Generates the quasi-polynomial function equivalent to our objective function condition on $x_{ij}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "poli_fun <- function(S, K, i, j){\n",
    "  pd <- poli_det(K, i, j)\n",
    "  pt <- poli_trace(S, K, i, j)\n",
    "  if (i==j){\n",
    "    function(x){\n",
    "      log(pd(x^2))-pt(x^2)\n",
    "    }\n",
    "  }else{\n",
    "    function(x){\n",
    "      log(pd(-x^2))-pt(-x^2)\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poli_par\n",
    "\n",
    "The following pair of functions calculate the partial derivatives of $f(x)$. This functions will be used to choose which is the best coordinate to performe the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "poli_par <- function(f, x0){\n",
    "  eps = 0.0001\n",
    "  (f(x0+eps)-f(x0-eps))/(2*eps)\n",
    "}\n",
    "\n",
    "poli_par_ij <- function(S, K, i, j){\n",
    "  f <- poli_fun(S, K, i, j)\n",
    "  if (i==j){\n",
    "    par <- poli_par(f, (K[i, j])^.5)\n",
    "  }else{\n",
    "    par <- poli_par(f, (-(K[i, j]))^.5)\n",
    "  }\n",
    "  par\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find ij\n",
    "\n",
    "This function chooses the best coordinate to perform the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_ij <- function(S, K){\n",
    "  n <- dim(K)[1]\n",
    "  \n",
    "  the_i <- 0\n",
    "  the_j <- 0\n",
    "  the_v <- -Inf\n",
    "  \n",
    "  for (i in 1:n){\n",
    "    for (j in i:n){\n",
    "      if (i == j){\n",
    "        new_v <- abs(poli_par(poli_fun(S, K, i, j), (K[i, j])^.5))\n",
    "      }else{\n",
    "        new_v <- abs(poli_par(poli_fun(S, K, i, j), (-K[i, j])^.5))\n",
    "      }\n",
    "      \n",
    "      if (new_v > the_v){\n",
    "        the_v <- new_v\n",
    "        the_i <- i\n",
    "        the_j <- j\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  c(the_i, the_j)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting all together\n",
    "\n",
    "Finally we are able to define a procedure that beats a general-purpose optimizer even in low dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization on coordinate x_{ij}\n",
    "optimize_f_ij <- function(S, K, i, j){\n",
    "  f <- poli_fun(S, K, i, j)\n",
    "  \n",
    "  if (i == j){\n",
    "    x0 <- (K[i, j])^.5\n",
    "  }else{\n",
    "    x0 <- (-K[i, j])^.5\n",
    "  }\n",
    "  \n",
    "  \n",
    "  result <- optim(x0, f, control=list(fnscale=-1, reltol=1e-8))\n",
    "  \n",
    "  if(i == j){\n",
    "    K[i,j] <- (result$par)^2\n",
    "  }else{\n",
    "    K[i, j] <- -(result$par)^2\n",
    "    K[j, i] <- -(result$par)^2\n",
    "  }\n",
    "  K\n",
    "}\n",
    "\n",
    "# API \n",
    "exercise_3 <- function(S, pre = 1e-1, max_iter = 100){\n",
    "  \n",
    "  n <- dim(S)[1]\n",
    "  \n",
    "  eps <- 0.1\n",
    "  \n",
    "  # We set the right epsilon so det(K) > 0 \n",
    "  while (TRUE){\n",
    "    K <- diag(n)\n",
    "    K <- K - eps*matrix(1, nrow = n, ncol = n) \n",
    "    \n",
    "    if (det(K)>0){\n",
    "      break\n",
    "      }else{\n",
    "        eps<-eps/2\n",
    "      } \n",
    "  }\n",
    "\n",
    "  \n",
    "  last_value <- Inf\n",
    "  \n",
    "  # We make sure that at least each component is maximized once\n",
    "  for (i in 1:n){\n",
    "    for (j in i:n){\n",
    "      aux <- optimize_f_ij(S, K, i, j)\n",
    "      K <- aux\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # Here we could be fancyer\n",
    "  for (mi in 1:max_iter){\n",
    "    ij = find_ij(S, K)\n",
    "    \n",
    "    i <- ij[1]\n",
    "    j <- ij[2]\n",
    "    \n",
    "    aux <- optimize_f_ij(S, K, i, j)\n",
    "    K <- aux\n",
    "  }\n",
    "  round(K, 2)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving and Performance Benchmark\n",
    "\n",
    "We tested both algorithms against a randomly created S. Therefore, we can confirm that the results are identical. The chart finally, compares the performance of both algorithms with respect to the dimensions of the targeted matrix K. While the standard CVXR algorithm grows fast (though not exponential), the solving time of our customized method increases much slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"exercise_2\"\n",
      "[1] \"this is going to be slow\"\n",
      "[1] \"exercise_3\"\n",
      "       [,1] [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9]\n",
      " [1,]  0.08 0.00  0.00  0.00  0.00  0.00 -0.02 -0.03 -0.04\n",
      " [2,]  0.00 0.07  0.00  0.00  0.00  0.00  0.00  0.00  0.00\n",
      " [3,]  0.00 0.00  0.28  0.00  0.00 -0.07  0.00  0.00  0.00\n",
      " [4,]  0.00 0.00  0.00  0.15 -0.10  0.00  0.00  0.00 -0.08\n",
      " [5,]  0.00 0.00  0.00 -0.10  0.26 -0.02  0.00  0.00 -0.04\n",
      " [6,]  0.00 0.00 -0.07  0.00 -0.02  0.08  0.00  0.00  0.00\n",
      " [7,] -0.02 0.00  0.00  0.00  0.00  0.00  0.17  0.00  0.00\n",
      " [8,] -0.03 0.00  0.00  0.00  0.00  0.00  0.00  0.32 -0.12\n",
      " [9,] -0.04 0.00  0.00 -0.08 -0.04  0.00  0.00 -0.12  0.29\n",
      "[1] \"Done!!! ;-)\"\n"
     ]
    }
   ],
   "source": [
    "#set.seed(1)\n",
    "\n",
    "n <- 5     ## Dimension of matrix\n",
    "S <- matrix(rnorm(n*n), ncol=n)\n",
    "S <- S%*%t(S)\n",
    "\n",
    "n <- dim(S)[1]\n",
    "K <- diag(n)\n",
    "\n",
    "print('exercise_2')\n",
    "print('this is going to be slow')\n",
    "Kr_2 <- exercise_2(S, pre=1e-2, max_iter = 100)\n",
    "print(Kr_2)\n",
    "print('exercise_3')\n",
    "Kr_3 <- exercise_3(S, pre=1e-2, max_iter = 100)\n",
    "print(Kr_3)\n",
    "print('Done!!! ;-)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in Variable(n, n, PSD = TRUE): konnte Funktion \"Variable\" nicht finden\n",
     "output_type": "error",
     "traceback": [
      "Error in Variable(n, n, PSD = TRUE): konnte Funktion \"Variable\" nicht finden\nTraceback:\n",
      "1. performance_test(2, 9)",
      "2. exercise_2(S, pre = 0.01, max_iter = 1000)   # at line 11 of file <text>"
     ]
    }
   ],
   "source": [
    "performance_test <- function(lower, upper){\n",
    "\n",
    "  test_results_df <- data.frame(matrix(ncol = 3, nrow = 0)) ## Dataframe for test results\n",
    "  colnames(test_results_df) <- c(\"dimensions\", \"solving_time_e2\", \"solving_time_e3\")\n",
    "\n",
    "  for (n in lower:upper) {\n",
    "    S <- matrix(rnorm(n * n), ncol = n)\n",
    "    S <- S %*% t(S)\n",
    "\n",
    "    start_time <- Sys.time()\n",
    "    res_e2 <- exercise_2(S, pre = 1e-2, max_iter = 1000)\n",
    "    end_time <- Sys.time()\n",
    "    time_e2 <- end_time - start_time\n",
    "\n",
    "    start_time <- Sys.time()\n",
    "    res_e3 <- exercise_3(S, pre = 1e-2, max_iter = 100)\n",
    "    end_time <- Sys.time()\n",
    "    time_e3 <- end_time - start_time\n",
    "\n",
    "\n",
    "    df <- data.frame(n, time_e2, time_e3) ## result index 1 expected as time\n",
    "    colnames(df) <- c(\"dimensions\", \"solving_time_e2\", \"solving_time_e3\")\n",
    "    test_results_df <- rbind(test_results_df, df)\n",
    "\n",
    "  }\n",
    "  return(test_results_df)\n",
    "}\n",
    "\n",
    "test_results_df <- performance_test(2, 9)\n",
    "\n",
    "ggplot(test_results_df, aes(x=dimensions)) +\n",
    "  geom_line(aes(y = as.numeric(solving_time_e2)), color = \"red\") +\n",
    "  geom_line(aes(y = as.numeric(solving_time_e3)), color = \"green\") +\n",
    "  labs(x=\"Dimensions of S\", y=\"Solving Time in Seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
